# B∆∞·ªõc 2: Vi·∫øt app v√†o file app.py (ƒë·∫∑t t√™n file ƒë·ªìng nh·∫•t)
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from collections import Counter
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np

# Thi·∫øt l·∫≠p trang ƒë·∫ßu file
st.set_page_config(
    page_title="üìä Spotify Sentiment Dashboard",
    layout="wide"
)

st.markdown(
    """
    <style>
    h1, h2, h3 {color: #2C3E50;}
    .block-container {padding: 1rem 2rem;}
    </style>
    """,
    unsafe_allow_html=True
)

st.title("üìä Spotify Sentiment Dashboard")

nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)
stop_words = set(stopwords.words('english'))

@st.cache_data
def load_data():
    combined = pd.read_csv('result/combined_spotify_reviews.csv')
    lexicon = pd.read_csv('result/lexicon_results.csv')
    distilbert = pd.read_csv('result/distilbert_results.csv')
    combined['date'] = pd.to_datetime(combined['date'], errors='coerce').dt.tz_localize(None)
    return combined, lexicon, distilbert

combined_df, lexicon_df, distilbert_df = load_data()

df = combined_df.rename(columns={'id':'review_id'})
df = df.merge(
    lexicon_df[['review_id','tb_label','vader_compound','tb_prob_pos']],
    on='review_id', how='left'
)
df = df.merge(
    distilbert_df[['review_id','dl_label','confidence']],
    on='review_id', how='left'
)

df['vader_label'] = df['vader_compound'].apply(
    lambda x: 'positive' if x > 0.05 else ('negative' if x < -0.05 else 'neutral')
)

df['rating_label'] = df['rating'].apply(
    lambda x: 'negative' if x in [1, 2] else ('neutral' if x == 3 else 'positive')
)

filtered = df.copy()
color_map = {'negative':'#e74c3c', 'neutral':'#95a5a6', 'positive':'#2ecc71'}

tab1, tab2, tab3 = st.tabs([
    "üîç So s√°nh ph∆∞∆°ng ph√°p",
    "üì± So s√°nh n·ªÅn t·∫£ng",
    "üí¨ T·ª´ kh√≥a ti√™u c·ª±c"
])

# Bi·ªÉu ƒë·ªì ph√¢n b·ªë sentiment
def plot_sentiment_distribution(data, label_col, title):
    """
    V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë sentiment d·∫°ng c·ªôt ch·ªìng.
    
    Args:
        data: DataFrame ch·ª©a d·ªØ li·ªáu
        label_col: T√™n c·ªôt ch·ª©a nh√£n sentiment
        title: Ti√™u ƒë·ªÅ bi·ªÉu ƒë·ªì
    """
    # T√≠nh to√°n t·ª∑ l·ªá ph·∫ßn trƒÉm cho m·ªói nh√£n
    ct = data[label_col].value_counts(normalize=True).sort_index() * 100
    
    # T·∫°o DataFrame cho bi·ªÉu ƒë·ªì
    plot_data = pd.DataFrame({
        'Sentiment': ct.index,
        'Percent': ct.values,
        'Method': [title] * len(ct)
    })
    
    return plot_data

# H√†m t√≠nh metric cho l·ªõp positive
def compute_all_metrics(true_labels, pred_labels, labels=None):
    results = {}
    results['Accuracy'] = accuracy_score(true_labels, pred_labels)
    if labels is None:
        labels = sorted(set(true_labels) | set(pred_labels))
    for label in labels:
        results[f'Precision_{label}'] = precision_score(true_labels, pred_labels, labels=[label], average='macro', zero_division=0)
        results[f'Recall_{label}'] = recall_score(true_labels, pred_labels, labels=[label], average='macro', zero_division=0)
        results[f'F1_{label}'] = f1_score(true_labels, pred_labels, labels=[label], average='macro', zero_division=0)
    results['Precision_macro'] = precision_score(true_labels, pred_labels, average='macro', zero_division=0)
    results['Recall_macro'] = recall_score(true_labels, pred_labels, average='macro', zero_division=0)
    results['F1_macro'] = f1_score(true_labels, pred_labels, average='macro', zero_division=0)
    return results

def show_test_and_score_matrix(df, methods, method_names, labels):
    rows = []
    for i in range(len(methods)):
        for j in range(i+1, len(methods)):
            m_true, m_pred = methods[i], methods[j]
            name_true, name_pred = method_names[i], method_names[j]
            sub_df = df.dropna(subset=[m_true, m_pred])
            metrics = compute_all_metrics(sub_df[m_true], sub_df[m_pred], labels=labels)
            metrics['Ph∆∞∆°ng ph√°p 1'] = name_true
            metrics['Ph∆∞∆°ng ph√°p 2'] = name_pred
            rows.append(metrics)

    results_df = pd.DataFrame(rows)
    # ƒê·ªïi t√™n c·ªôt
    results_df.rename(columns={
        'Accuracy': 'Accuracy',
        'Precision_macro': 'Precision (Macro)',
        'Recall_macro': 'Recall (Macro)',
        'F1_macro': 'F1-score (Macro)',
    }, inplace=True)

    # ƒê·ªãnh d·∫°ng %
    for col in results_df.columns:
        if col not in ['Ph∆∞∆°ng ph√°p 1', 'Ph∆∞∆°ng ph√°p 2']:
            results_df[col] = results_df[col].apply(lambda x: f"{x*100:.2f}%")

    st.dataframe(results_df.style.background_gradient(cmap='RdYlGn_r'), use_container_width=True)

def show_method_comparison(df, methods, method_names, labels):
    """
    So s√°nh v√† ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c gi·ªØa c√°c ph∆∞∆°ng ph√°p ph√¢n t√≠ch sentiment.
    
    Args:
        df: DataFrame ch·ª©a d·ªØ li·ªáu
        methods: List c√°c c·ªôt ch·ª©a nh√£n sentiment
        method_names: List t√™n c√°c ph∆∞∆°ng ph√°p
        labels: List c√°c nh√£n sentiment
    """
    # T√≠nh to√°n c√°c ch·ªâ s·ªë cho t·ª´ng ph∆∞∆°ng ph√°p
    results = []
    for method, name in zip(methods, method_names):
        # L·ªçc d·ªØ li·ªáu kh√¥ng null
        valid_data = df.dropna(subset=[method])
        
        # T√≠nh to√°n c√°c ch·ªâ s·ªë
        metrics = {
            'Ph∆∞∆°ng ph√°p': name,
            'S·ªë l∆∞·ª£ng m·∫´u': len(valid_data),
            'T·ª∑ l·ªá positive': (valid_data[method] == 'positive').mean() * 100,
            'T·ª∑ l·ªá negative': (valid_data[method] == 'negative').mean() * 100,
            'T·ª∑ l·ªá neutral': (valid_data[method] == 'neutral').mean() * 100
        }
        results.append(metrics)
    
    # T·∫°o DataFrame k·∫øt qu·∫£
    results_df = pd.DataFrame(results)
    
    # ƒê·ªãnh d·∫°ng ph·∫ßn trƒÉm
    for col in ['T·ª∑ l·ªá positive', 'T·ª∑ l·ªá negative', 'T·ª∑ l·ªá neutral']:
        results_df[col] = results_df[col].apply(lambda x: f"{x:.1f}%")
    
    # Hi·ªÉn th·ªã b·∫£ng k·∫øt qu·∫£
    st.dataframe(results_df, use_container_width=True)
    
    # Ph√¢n t√≠ch v√† k·∫øt lu·∫≠n
    st.subheader("Ph√¢n t√≠ch k·∫øt qu·∫£")
    
    # T√≠nh to√°n c√°c ch·ªâ s·ªë so s√°nh
    distilbert_stats = df[df['dl_label'].notna()]['dl_label'].value_counts(normalize=True) * 100
    lexicon_stats = df[df['tb_label'].notna()]['tb_label'].value_counts(normalize=True) * 100
    
    # T√≠nh ƒë·ªô l·ªách chu·∫©n ƒë·ªÉ ƒë√°nh gi√° s·ª± c√¢n b·∫±ng
    distilbert_std = np.std([distilbert_stats.get('positive', 0), 
                           distilbert_stats.get('negative', 0), 
                           distilbert_stats.get('neutral', 0)])
    lexicon_std = np.std([lexicon_stats.get('positive', 0), 
                         lexicon_stats.get('negative', 0), 
                         lexicon_stats.get('neutral', 0)])
    
    # So s√°nh t·ª∑ l·ªá negative
    distilbert_neg = distilbert_stats.get('negative', 0)
    lexicon_neg = lexicon_stats.get('negative', 0)
    
    # Hi·ªÉn th·ªã k·∫øt lu·∫≠n
    st.markdown(f"""
    **K·∫øt lu·∫≠n:**
    1. Ph√¢n b·ªë sentiment:
       - DistilBERT: {distilbert_std:.1f}% ƒë·ªô l·ªách chu·∫©n
       - Lexicon: {lexicon_std:.1f}% ƒë·ªô l·ªách chu·∫©n
       - Ph∆∞∆°ng ph√°p c√≥ ph√¢n b·ªë c√¢n b·∫±ng h∆°n: **{"DistilBERT" if distilbert_std < lexicon_std else "Lexicon"}**
    
    2. T·ª∑ l·ªá ƒë√°nh gi√° ti√™u c·ª±c:
       - DistilBERT: {distilbert_neg:.1f}%
       - Lexicon: {lexicon_neg:.1f}%
       - Ph∆∞∆°ng ph√°p ph√°t hi·ªán nhi·ªÅu ƒë√°nh gi√° ti√™u c·ª±c h∆°n: **{"DistilBERT" if distilbert_neg > lexicon_neg else "Lexicon"}**
    
    3. D·ª±a tr√™n ph√¢n t√≠ch:
       - Ph∆∞∆°ng ph√°p c√≥ ƒë·ªô l·ªách chu·∫©n th·∫•p h∆°n cho th·∫•y ph√¢n b·ªë sentiment c√¢n b·∫±ng h∆°n
       - T·ª∑ l·ªá ƒë√°nh gi√° ti√™u c·ª±c cao h∆°n c√≥ th·ªÉ ph·∫£n √°nh th·ª±c t·∫ø t·ªët h∆°n
       - N√™n xem x√©t k·∫øt h·ª£p c·∫£ hai ph∆∞∆°ng ph√°p ƒë·ªÉ c√≥ ƒë√°nh gi√° to√†n di·ªán
    """)

# Tab 1
with tab1:
    st.header("1. So s√°nh sentiment gi·ªØa c√°c ph∆∞∆°ng ph√°p ph√¢n t√≠ch")
    st.subheader("Ph√¢n b·ªë sentiment t·ª´ng ph∆∞∆°ng ph√°p")
    
    # T·∫°o d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì
    vader_data = plot_sentiment_distribution(filtered.dropna(subset=['vader_label']), 'vader_label', 'VADER')
    textblob_data = plot_sentiment_distribution(filtered.dropna(subset=['tb_label']), 'tb_label', 'TextBlob')
    distilbert_data = plot_sentiment_distribution(filtered.dropna(subset=['dl_label']), 'dl_label', 'DistilBERT')
    
    # K·∫øt h·ª£p d·ªØ li·ªáu
    combined_data = pd.concat([vader_data, textblob_data, distilbert_data])
    
    # V·∫Ω bi·ªÉu ƒë·ªì c·ªôt ch·ªìng d·ªçc
    fig = px.bar(
        combined_data,
        x='Method',
        y='Percent',
        color='Sentiment',
        title='Ph√¢n b·ªë sentiment theo ph∆∞∆°ng ph√°p',
        labels={'Method': 'Ph∆∞∆°ng ph√°p', 'Percent': 'T·ª∑ l·ªá (%)'},
        color_discrete_map=color_map,
        template='plotly_dark',
        barmode='stack',
        orientation='v'  # ƒê·∫∑t h∆∞·ªõng d·ªçc
    )
    
    # C·∫≠p nh·∫≠t layout
    fig.update_layout(
        height=500,  # TƒÉng chi·ªÅu cao ƒë·ªÉ hi·ªÉn th·ªã r√µ h∆°n
        yaxis=dict(
            ticksuffix='%',
            range=[0, 100]  # ƒê·∫£m b·∫£o tr·ª•c y t·ª´ 0-100%
        ),
        xaxis=dict(
            tickangle=0  # Gi·ªØ nh√£n tr·ª•c x ngang
        ),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        bargap=0.3  # TƒÉng kho·∫£ng c√°ch gi·ªØa c√°c c·ªôt
    )
    
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("ƒê√°nh gi√° ƒë·ªô ch√≠nh x√°c c·ªßa c√°c ph∆∞∆°ng ph√°p")
    show_method_comparison(filtered, ['vader_label', 'tb_label', 'dl_label'], 
                         ['VADER', 'TextBlob', 'DistilBERT'], 
                         ['positive','neutral','negative'])

# Tab 2
def plot_platform_sentiment(data, label_col, title):
    grp = data.groupby(['source', label_col]).size().unstack(fill_value=0)
    pct = grp.div(grp.sum(axis=1), axis=0) * 100
    chart = pct.reset_index().melt(
        id_vars='source', var_name='Sentiment', value_name='Percent'
    )
    fig = px.bar(
        chart,
        x='source', y='Percent', color='Sentiment', barmode='stack',
        title=title,
        labels={'source':'N·ªÅn t·∫£ng','Percent':'T·ª∑ l·ªá (%)'},
        color_discrete_map=color_map,
        template='plotly_dark'
    )
    fig.update_layout(yaxis=dict(ticksuffix='%'), height=450)
    return fig

with tab2:
    st.header("2. So s√°nh sentiment gi·ªØa c√°c n·ªÅn t·∫£ng")
    method = st.selectbox(
        "Ch·ªçn ph∆∞∆°ng ph√°p ph√¢n t√≠ch sentiment:",
        ['DistilBERT', 'Lexicon']
    )
    method_map = {
        'DistilBERT': 'dl_label',
        'Lexicon': 'tb_label'
    }
    selected_method = method_map[method]
    method_data = filtered.dropna(subset=[selected_method])

    st.subheader("1. Ph√¢n b·ªë sentiment theo n·ªÅn t·∫£ng")
    st.plotly_chart(plot_platform_sentiment(method_data, selected_method, f'{method} Platform'), use_container_width=True)

    st.subheader("2. Th·ªëng k√™ chi ti·∫øt theo n·ªÅn t·∫£ng")
    platform_stats = method_data.groupby('source')[selected_method].value_counts(normalize=True).unstack() * 100
    platform_stats = platform_stats.round(2)
    st.dataframe(platform_stats, use_container_width=True)

    st.subheader("3. Ph√¢n t√≠ch xu h∆∞·ªõng sentiment theo th·ªùi gian")
    # Chuy·ªÉn ƒë·ªïi datetime th√†nh date ƒë·ªÉ l·∫•y ng√†y
    method_data['date'] = pd.to_datetime(method_data['date']).dt.date
    
    # Nh√≥m d·ªØ li·ªáu theo ng√†y v√† sentiment, ƒë·∫øm s·ªë l∆∞·ª£ng review
    time_series = method_data.groupby(['date', selected_method]).size().unstack(fill_value=0)
    time_series = time_series.reset_index()
    
    # ƒê·∫£m b·∫£o t·∫•t c·∫£ c√°c c·ªôt sentiment c√≥ m·∫∑t
    for sentiment in ['positive', 'negative', 'neutral']:
        if sentiment not in time_series.columns:
            time_series[sentiment] = 0
    
    # T·∫°o bi·ªÉu ƒë·ªì ƒë∆∞·ªùng th·ªÉ hi·ªán s·ªë l∆∞·ª£ng review theo th·ªùi gian
    fig_time = px.line(
        time_series,
        x='date',
        y=['positive', 'neutral', 'negative'],
        title=f'S·ªë l∆∞·ª£ng review theo sentiment theo th·ªùi gian - {method}',
        labels={
            'date': 'Ng√†y',
            'value': 'S·ªë l∆∞·ª£ng review',
            'variable': 'Sentiment'
        },
        template='plotly_dark',
        height=500
    )
    
    # C·∫≠p nh·∫≠t giao di·ªán bi·ªÉu ƒë·ªì
    fig_time.update_layout(
        xaxis_title='Ng√†y',
        yaxis_title='S·ªë l∆∞·ª£ng review',
        legend=dict(
            orientation="h",  # ƒê·∫∑t legend n·∫±m ngang
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        hovermode='x unified'  # Hi·ªÉn th·ªã th√¥ng tin khi hover
    )
    
    st.plotly_chart(fig_time, use_container_width=True)

    # Th√™m b·∫£ng th·ªëng k√™ m√¥ t·∫£ s·ªë l∆∞·ª£ng review theo ng√†y
    st.subheader("4. Th·ªëng k√™ s·ªë l∆∞·ª£ng review")
    # T√≠nh th·ªëng k√™ cho t·∫•t c·∫£ review theo method ƒëang ch·ªçn
    review_stats = method_data[selected_method].value_counts()
    review_stats_df = pd.DataFrame({
        'Sentiment': review_stats.index,
        'S·ªë l∆∞·ª£ng': review_stats.values,
        'T·ª∑ l·ªá (%)': (review_stats.values / len(method_data) * 100).round(2)
    })
    st.dataframe(review_stats_df, use_container_width=True)

# Tab 3
with tab3:
    st.header("3. Ph√¢n t√≠ch t·ª´ kh√≥a ti√™u c·ª±c")

    col1, col2 = st.columns([1, 2])

    with col1:
        max_words = st.slider("S·ªë l∆∞·ª£ng t·ª´/c·ª•m t·ª´ hi·ªÉn th·ªã", 10, 100, 20)
        ngram_range = st.slider("ƒê·ªô d√†i c·ª•m t·ª´ (n-gram)", 1, 3, 2)

    filtered_data = filtered.copy()

    try:
        neg_ids = distilbert_df.loc[distilbert_df['dl_label']=='negative', 'review_id']
        texts_to_plot = filtered_data[filtered_data['review_id'].isin(neg_ids)]['clean_content'].dropna().tolist()

        if not texts_to_plot:
            st.warning('Kh√¥ng c√≥ review negative ƒë·ªÉ ph√¢n t√≠ch')
            st.stop()

        with col2:
            st.subheader("Th·ªëng k√™ c∆° b·∫£n")
            stats = pd.DataFrame({
                'Ch·ªâ s·ªë': ['S·ªë l∆∞·ª£ng review', 'T·ªïng s·ªë t·ª´', 'T·ª´ trung b√¨nh/review'],
                'Gi√° tr·ªã': [
                    len(texts_to_plot),
                    sum(len(t.split()) for t in texts_to_plot),
                    f"{sum(len(t.split()) for t in texts_to_plot)/len(texts_to_plot):.1f}"
                ]
            })
            st.dataframe(stats, use_container_width=True)

        st.subheader("1. WordCloud t·ª´ kh√≥a ti√™u c·ª±c")
        wc = WordCloud(
            width=800, height=300,
            background_color='white',
            colormap='Reds',
            max_words=max_words
        ).generate(' '.join(texts_to_plot))
        fig_wc, ax_wc = plt.subplots(figsize=(10,3))
        ax_wc.imshow(wc, interpolation='bilinear')
        ax_wc.axis('off')
        st.pyplot(fig_wc)

        st.subheader(f"2. Top {max_words} {ngram_range}-gram ti√™u c·ª±c")
        ngrams_list = []
        for txt in texts_to_plot:
            tokens = [w for w in word_tokenize(txt) if w.isalpha()]
            ngrams_list.extend(list(ngrams(tokens, ngram_range)))
        if not ngrams_list:
            st.warning("Kh√¥ng t√¨m th·∫•y n-gram n√†o th·ªèa m√£n ƒëi·ªÅu ki·ªán")
        else:
            top_ngrams = Counter(ngrams_list).most_common(max_words)
            ngram_terms = [' '.join(ng) for ng,_ in top_ngrams]
            ngram_counts = [cnt for _,cnt in top_ngrams]
            fig_ngram = px.bar(
                x=ngram_counts, y=ngram_terms, orientation='h',
                title=f'Top {max_words} {ngram_range}-gram ti√™u c·ª±c',
                labels={'x':'T·∫ßn su·∫•t','y':f'{ngram_range}-gram'},
                color=ngram_counts,
                color_continuous_scale='Reds',
                template='plotly_dark'
            )
            fig_ngram.update_layout(yaxis={'autorange':'reversed'}, height=400)
            st.plotly_chart(fig_ngram, use_container_width=True)

        st.subheader("3. Ph√¢n t√≠ch TF-IDF")
        vectorizer = TfidfVectorizer(
            stop_words='english',
            max_features=max_words,
            min_df=2,
            ngram_range=(1, ngram_range)
        )
        X = vectorizer.fit_transform(texts_to_plot)
        scores = dict(zip(
            vectorizer.get_feature_names_out(),
            X.sum(axis=0).A1
        ))
        if not scores:
            st.warning("Kh√¥ng t√¨m th·∫•y t·ª´ kh√≥a n√†o th·ªèa m√£n ƒëi·ªÅu ki·ªán TF-IDF")
        else:
            top_tfidf = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:max_words]
            tf_terms = [term for term,_ in top_tfidf]
            tf_scores = [score for _,score in top_tfidf]
            fig_tf = px.bar(
                x=tf_scores, y=tf_terms, orientation='h',
                title='Top TF-IDF terms',
                labels={'x':'TF-IDF Score','y':'Term'},
                color=tf_scores,
                color_continuous_scale='Reds',
                template='plotly_dark'
            )
            fig_tf.update_layout(yaxis={'autorange':'reversed'}, height=400)
            st.plotly_chart(fig_tf, use_container_width=True)

    except Exception as e:
        st.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}")

# Expander xem d·ªØ li·ªáu th√¥
with st.expander("üìÑ Xem d·ªØ li·ªáu th√¥"):
    st.dataframe(df)  # Show all rows
